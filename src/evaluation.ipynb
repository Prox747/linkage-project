{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Blocking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each entity we select the largest cluster (block) for that entity. True positives are items that are in the largest cluster and are correctly associated with that entity, false positives are items in the cluster that are not related to the entity and false negatives are items that should be in the cluster but aren't. \n",
    "\n",
    "We indicate true positives with $TP$, false positives with $FP$ and false negatives with $FN$,\n",
    "then we have the equations for $precision$, $recall$ and $f{\\text -}measure$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ precision = \\frac{TP}{TP + FP} \\\\ $$\n",
    "$$ recall = \\frac{TP}{TP + FN} \\\\ $$\n",
    "$$ f{\\text -}measure = \\frac{2 \\cdot precision \\cdot recall}{precision + recall} = \\frac{2 \\cdot TP}{2 TP + FP + FN} \\\\ $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paths\n",
    "import json\n",
    "import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = \"hdbscan\"\n",
    "\n",
    "evaluation.generate_entity2clusters(algorithm)\n",
    "\n",
    "with open(paths.RESULTS_DIR + \"/evaluation/\" + algorithm + \"_entity2clusters.json\",\"r\") as file:\n",
    "    entity2clusters: dict[str, dict[str, list[str]]] = json.load(file)\n",
    "    \n",
    "with open(paths.RESULTS_DIR + \"/clustering/\" + algorithm + \"/\" + algorithm + \"_clusters.json\", \"r\") as file:\n",
    "    alg_clusters = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 0\n",
    "FP = 0\n",
    "FN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove clusters with id -1 and count the number of false negatives items in those clusters\n",
    "for clusters in entity2clusters.values():\n",
    "    for cluster_id, values in clusters.items():\n",
    "        if cluster_id == '-1':\n",
    "            FN += len(values)\n",
    "            del clusters[cluster_id]\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0019691966869804177\n",
      "Recall: 0.8970652650021901\n",
      "F-measure: 0.003929766929130837\n"
     ]
    }
   ],
   "source": [
    "for entity, clusters in entity2clusters.items():\n",
    "    if len(clusters) == 0:\n",
    "        continue\n",
    "    # Get the cluster with the most elements\n",
    "    max_cluster = max(clusters.values(), key=len)\n",
    "    \n",
    "    # Get the id of the cluster with the most elements\n",
    "    for key,value in clusters.items():\n",
    "        if len(value) == len(max_cluster):\n",
    "             max_cluster_id = key\n",
    "             \n",
    "    # Calculate False Positives (FP) as elements in the largest cluster that should not be there\n",
    "    for item in alg_clusters[max_cluster_id]:\n",
    "        if item not in max_cluster:\n",
    "            FP += 1   \n",
    "                                 \n",
    "    # Calculate True Positives (TP) as elements in the largest cluster\n",
    "    TP += len(max_cluster)\n",
    "    \n",
    "    # Calculate False Negatives (FN) as elements in the other clusters\n",
    "    for cluster in clusters.values():\n",
    "        if cluster != max_cluster:\n",
    "            FN += len(cluster)\n",
    "     \n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f_measure = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F-measure: {f_measure}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PostProcesing of results from LLM query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_results_file = paths.RESULTS_DIR + \"/pairwise_matching/RAW_matching_results_cluster_397.json\"\n",
    "\n",
    "with open(llm_results_file, 'r', encoding='utf-8') as file:\n",
    "    llm_results_cluster_397: dict[str, list[list[str]]] = json.load(file)\n",
    "\n",
    "result_cluster_397 = llm_results_cluster_397[\"397\"]\n",
    "\n",
    "post_processed_results: list[tuple[str, str, str]] = []\n",
    "\n",
    "for [item1, item2, result] in result_cluster_397:\n",
    "    if \"same\" in result:\n",
    "        post_processed_results.append((item1, item2, \"MATCH\"))\n",
    "    elif \"different\" in result:\n",
    "        post_processed_results.append((item1, item2, \"NO_MATCH\"))\n",
    "\n",
    "post_processed_results_file = paths.RESULTS_DIR + \"/pairwise_matching/matching_results_cluster_397_post_processed.json\"\n",
    "\n",
    "with open(post_processed_results_file, \"w\") as file:\n",
    "    json.dump(post_processed_results, file, indent=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 0\n",
    "FP = 0\n",
    "FN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7\n",
      "Recall: 1.0\n",
      "F-measure: 0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "entity2cluster397: list[str] = entity2clusters[\"ENTITY#011\"][\"397\"]\n",
    "\n",
    "for item1, item2, result in post_processed_results:\n",
    "    if result == \"MATCH\":\n",
    "        if item1 in entity2cluster397 and item2 in entity2cluster397:\n",
    "            TP += 1\n",
    "        else:\n",
    "            FP += 1\n",
    "    elif item1 in entity2cluster397 and item2 in entity2cluster397:\n",
    "        FN += 1\n",
    "\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f_measure = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F-measure: {f_measure}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linkage-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
